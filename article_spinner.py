"""This script generates spun content based upon talks given in an LDS General
Conference session. There should be 999 talks generated by the time the script
completes."""

import nltk
import random
import glob
import os

speakers = ['russell-m-nelson', 'dallin-h-oaks', 'henry-b-eyring',
            'm-russell-ballard', 'jeffrey-r-holland', 'dieter-f-uchtdorf',
            'david-a-bednar', 'quentin-l-cook', 'd-todd-christofferson',
            'neil-l-andersen', 'ronald-a-rasband', 'gary-e-stevenson',
            'dale-g-renlund', 'gerrit-w-gong', 'ulisses-soares',
            'angel-abrea', 'reyna-i-aburto', 'marcos-a-aidukaitis',
            'silvia-h-allred', 'jose-l-alonso', 'carlos-h-amado',
            'wilford-w-andersen', 'koichi-aoyagi', 'ian-s-ardern',
            'mervyn-b-arnold', 'carlos-e-asay', 'brian-k-ashton',
            'marvin-j-ashton', 'eduardo-ayala', 'robert-l-backman',
            'steven-r-bangerter', 'ben-b-banks', 'w-mark-bassett',
            'merrill-j-bateman', 'david-s-baxter', 'david-l-beck',
            'julie-b-beck', 'randall-k-bennett', 'ezra-taft-benson',
            'jean-b-bingham', 'shayne-m-bowen', 'william-r-bradford',
            'mark-a-bragg', 'ted-e-brewerton', 'm-joseph-brough',
            'monte-j-brough', 'l-edward-brown', 'dean-r-burgess',
            'h-david-burton', 'linda-k-burton', 'f-enzio-busche',
            'douglas-l-callister', 'tad-r-callister', 'helio-r-camargo',
            'george-i-cannon', 'robert-w-cantwell', 'craig-a-cardon',
            'bruce-a-carlson', 'matthew-l-carpenter', 'gerald-j-causse',
            'sheldon-f-child', 'yoon-h-choi', 'albert-choules-jr',
            'craig-o-christensen', 'shirley-d-christensen',
            'darwin-b-christenson', 'kim-b-clark', 'don-r-clark',
            'j-richard-clarke', 'l-whitney-clayton', 'weatherford-t-clayton',
            'gayle-m-clegg', 'gary-j-coleman', 'spencer-j-condie',
            'carl-b-cook', 'gene-r-cook', 'mary-n-cook', 'richard-e-cook',
            'lawrence-e-corbridge', 'bonnie-h-cordon', 'valeri-v-cordon',
            'j-devn-cornish', 'claudio-r-m-costa', 'joaquin-e-costa',
            'michelle-d-craig', 'rulon-g-craven', 'legrand-r-curtis',
            'derek-a-cuthbert', 'charles-w-dahlquist-ii', 'elaine-s-dalton',
            'adhemar-damiani', 'dean-myron-davies', 'massimo-de-feo',
            'benjamin-de-hoyos', 'robert-k-dellenbach', 'royden-g-derrick',
            'gordon-b-hinckley', 'thomas-s-monson', 'james-e-faust',
            'richard-g-scott']

master_txt_file = open('data\master_text.txt', 'r', encoding='utf-8').read()
master_txt_file = master_txt_file.splitlines()


"""Globs all the files and places them into a list"""
def glob_file():
    glob_file_list = []
    for i in speakers:
        partial_path = r'data\100_speaker_data\{}\source_data'.format(i)
        for filename in sorted(glob.glob(os.path.join(partial_path, '*.txt'))):
            glob_file_list.append(filename)
    return glob_file_list

"""Builds the trigram model. The structure of the trigram model is:
{(W n-2, W n-1): [Wn, Wn, Wn,..., Wn],...,(W n-2, W n-1): [Wn,..., Wn]} where
the key is a tuple of the two proceeding words and the value is the list of all
the words that may follow that tuple pair."""
def trigram_model():
    trigrams = {}
    for words in master_txt_file:
        word = words.lower()
        tokens = nltk.tokenize.word_tokenize(word)
        for i in range(len(tokens) - 2):
            dict_key = (tokens[i], tokens[i+1])
            if dict_key not in trigrams:
                trigrams[dict_key] = []
            trigrams[dict_key].append(tokens[i+2])
    return trigrams


"""Builds the trigram probabilities."""
trigram_probability = {}
for key, value in trigram_model().items():
    if len(set(value)) > 1:
        probability_dict = {}
        num = 0
        for word in value:
            if word not in probability_dict:
                probability_dict[word] = 0
            probability_dict[word] += 1
            num += 1
        for word, count in probability_dict.items():
            probability_dict[word] = float(count) / num
        trigram_probability[key] = probability_dict


"""Randomly selects from trigram_probabilities dictionary"""
def random_sample(d):
    random_number = random.random()
    cumulative = 0
    for key, value in d.items():
        cumulative += value
        if random_number < cumulative:
            return key


def article_generator():
    counter = 0

    for filename in glob_file():
        counter += 1
        open_file = open(filename, 'r', encoding='utf-8').read()
        article = open_file.lower()
        word_tokens = nltk.tokenize.word_tokenize(article)
        for i in range(len(word_tokens) - 2):
            if random.random() > .2:
                key = (word_tokens[i], word_tokens[i+1])
                if key in trigram_probability:
                    word = random_sample(trigram_probability[key])
                    word_tokens[i+2] = word
                    if not os.path.exists(r'data\spun_data'):
                        os.makedirs(r'data\spun_data')
                    with open(r'data\spun_data\spun_talk_0{}_.txt'.format(counter),
                              'w', encoding='utf-8') as spun_article:
                        print('Spun:\n', file=spun_article)
                        print(' '.join(word_tokens).replace(" .", ".").replace(" '", "'")
                              .replace(" ,", ",").replace("$ ", "$").replace(" !", "!")
                              .replace(" ?", "?"), file=spun_article)


article_generator()

